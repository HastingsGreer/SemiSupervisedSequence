{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HastingsGreer/SemiSupervisedSequence/blob/master/Downstream_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "92efce92",
      "metadata": {
        "id": "92efce92"
      },
      "outputs": [],
      "source": [
        "#!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Movies_and_TV_5.json.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "08ab9e3c",
      "metadata": {
        "id": "08ab9e3c"
      },
      "outputs": [],
      "source": [
        "#!gunzip Movies_and_TV_5.json.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b3f3ee4f",
      "metadata": {
        "id": "b3f3ee4f",
        "outputId": "f8e729e4-caf7-494d-e635-e95d0a05ec1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-29 09:52:52--  https://github.com/HastingsGreer/SemiSupervisedSequence/releases/download/weights/memorise_lstm.pth\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/529999830/28b71dd8-6dc0-4ff3-95f1-7b751ab9e509?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220829%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220829T095252Z&X-Amz-Expires=300&X-Amz-Signature=cd51e5700b842def5621169bdc5c7d69cf22311fd1041d2b21dd1371ad6b98fd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=529999830&response-content-disposition=attachment%3B%20filename%3Dmemorise_lstm.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-08-29 09:52:52--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/529999830/28b71dd8-6dc0-4ff3-95f1-7b751ab9e509?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220829%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220829T095252Z&X-Amz-Expires=300&X-Amz-Signature=cd51e5700b842def5621169bdc5c7d69cf22311fd1041d2b21dd1371ad6b98fd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=529999830&response-content-disposition=attachment%3B%20filename%3Dmemorise_lstm.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 172867155 (165M) [application/octet-stream]\n",
            "Saving to: ‘memorise_lstm.pth’\n",
            "\n",
            "memorise_lstm.pth   100%[===================>] 164.86M  13.2MB/s    in 13s     \n",
            "\n",
            "2022-08-29 09:53:06 (12.4 MB/s) - ‘memorise_lstm.pth’ saved [172867155/172867155]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/HastingsGreer/SemiSupervisedSequence/releases/download/weights/memorise_lstm.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d4b46d2",
      "metadata": {
        "id": "0d4b46d2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/Movies_and_TV_5.json ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fb5f493",
      "metadata": {
        "id": "1fb5f493"
      },
      "outputs": [],
      "source": [
        "pip install --quiet transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75e5e2c0",
      "metadata": {
        "id": "75e5e2c0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "text = []\n",
        "scores = []\n",
        "with open(\"Movies_and_TV_5.json\", \"r\") as f:\n",
        "  for l in f.readlines():\n",
        "    d = json.loads(l)\n",
        "    if \"reviewText\" in d:\n",
        "      text.append(d[\"reviewText\"])\n",
        "      scores.append(d[\"overall\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6e34597",
      "metadata": {
        "id": "f6e34597"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e5e7235",
      "metadata": {
        "id": "5e5e7235"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb48263e",
      "metadata": {
        "id": "cb48263e"
      },
      "outputs": [],
      "source": [
        "def tokens(k):\n",
        "  text_tok = tokenizer(text[10000 * k:10000 * (k + 1)], padding=True, truncation=True, return_tensors=\"pt\")\n",
        "  text_tok = text_tok['input_ids']\n",
        "  text_tok = text_tok[:, :128]\n",
        "  return text_tok, torch.tensor(scores[10000*k:10000 * (k + 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4322fd4",
      "metadata": {
        "id": "d4322fd4"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c3b995c",
      "metadata": {
        "id": "8c3b995c"
      },
      "outputs": [],
      "source": [
        "class AutoencodingLanguageModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.embedding = torch.nn.Embedding(num_embeddings=30522, embedding_dim=256)\n",
        "    self.inlayer = torch.nn.LSTM(input_size=256, hidden_size=1024, num_layers=2, batch_first=True)\n",
        "    self.outlayer = torch.nn.LSTM(input_size=256, hidden_size=1024, num_layers=2, batch_first=True)\n",
        "    self.output = torch.nn.Conv1d(in_channels=1024, out_channels = 256, kernel_size=1)\n",
        "    self.output2 = torch.nn.Conv1d(in_channels=256, out_channels = 30522, kernel_size=1)\n",
        "\n",
        "  def forward(self, input):\n",
        "    input = self.embedding(input)\n",
        "\n",
        "    repr = self.inlayer(torch.flip(input, dims=(1,)))[1]\n",
        "    repr = self.outlayer(input)\n",
        "    repr = repr[0]\n",
        "    \n",
        "    repr = torch.transpose(repr, 1, 2)\n",
        "    out = self.output2(self.output(repr))\n",
        "    return out\n",
        "\n",
        "m = AutoencodingLanguageModel()\n",
        "m.cuda()\n",
        "m.load_state_dict(torch.load(\"memorise_lstm.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DownstreamModel(torch.nn.Module):\n",
        "  def __init__(self,  m):\n",
        "    super().__init__()\n",
        "    self.embedding = m.embedding\n",
        "    self.inlayer = m.inlayer\n",
        "    self.output = torch.nn.Linear(1024, 5)\n",
        "  def forward(self, input):\n",
        "    input = self.embedding(input)\n",
        "    repr = self.inlayer(torch.flip(input, dims=(1,)))[1]\n",
        "    out = self.output(repr[1][1])\n",
        "    return out\n",
        "\n",
        "task_model = DownstreamModel(m).cuda()"
      ],
      "metadata": {
        "id": "Gp8XxLw_DjIc"
      },
      "id": "Gp8XxLw_DjIc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6b14705",
      "metadata": {
        "id": "c6b14705"
      },
      "outputs": [],
      "source": [
        "loss = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(task_model.parameters(), lr=.001)\n",
        "curve = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "khXxdDPaF_um"
      },
      "id": "khXxdDPaF_um",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "307ad947",
      "metadata": {
        "id": "307ad947"
      },
      "outputs": [],
      "source": [
        "for k in range(30, 305):\n",
        "  text_tok, subscores = tokens(k)\n",
        "  for _ in range(10):\n",
        "    for _ in range(10):\n",
        "      optimizer.zero_grad()\n",
        "      idxs = torch.randint(0, 10000, (64,))\n",
        "      input_ = text_tok[idxs].cuda()\n",
        "\n",
        "      outputs = task_model(input_)\n",
        "\n",
        "      l = loss(outputs, subscores[idxs].cuda().long() - 1)\n",
        "      l.backward()\n",
        "      optimizer.step()\n",
        "      curve.append(l.item())\n",
        "    print(torch.mean(torch.tensor(curve[-10:])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd8a0d32",
      "metadata": {
        "id": "fd8a0d32"
      },
      "outputs": [],
      "source": [
        "plt.hist2d(torch.argmax(outputs.detach().cpu(), dim=1).numpy(), (subscores[idxs].long() - 1).numpy(), bins=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d354ba78",
      "metadata": {
        "scrolled": true,
        "id": "d354ba78"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(curve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "768e3813",
      "metadata": {
        "id": "768e3813"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(input_[46])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2fccb57",
      "metadata": {
        "id": "d2fccb57"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(torch.argmax(outputs[46], axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ba7eb0c",
      "metadata": {
        "id": "3ba7eb0c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab22adcf",
      "metadata": {
        "id": "ab22adcf"
      },
      "outputs": [],
      "source": [
        "import footsteps\n",
        "torch.save(m.state_dict(), footsteps.output_dir + \"weights.pth\")\n",
        "torch.save(curve, footsteps.output_dir + 'learning curve')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8096994",
      "metadata": {
        "id": "d8096994"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d601f369",
      "metadata": {
        "id": "d601f369"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}